{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from twitter import Twitter, OAuth, TwitterHTTPError, TwitterStream\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "import gensim\n",
    "import spacy\n",
    "#import pyspark\n",
    "#from pyspark import *\n",
    "import textprocessing\n",
    "import re\n",
    "from textprocessing import preprocessing\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as Vader\n",
    "from textprocessing import textfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers='localhost:9092',api_version=(0,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consumer_key = \"cW3RTKoG5kiNkzfdbSb8aBMyY\"\n",
    "consumer_secret = \"iwj5uOncngUMYk2BMNkF3WwL9VR7FXCPvXJVYwbDNDmuy8yRkH\"\n",
    "access_key = \"4175914697-j5Ghb209PGZOkobm0cnh9nZ2zMwrrigfVGczYbA\"\n",
    "access_secret = \"0lK2XYfh1oksmpymqgTRBLrhR5nGLMUr84N0yhicWuUq2\"\n",
    "#execfile(\"config_template.py\", config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter = Twitter(auth = OAuth(access_key, access_secret, consumer_key, consumer_secret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "producer = KafkaProducer(value_serializer=lambda v: json.dumps(v).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterator=twitter.search.tweets(q = \"#starwars\", result_type='recent', lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Search complete (%.3f seconds)\" % (iterator[\"search_metadata\"][\"completed_in\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnt = len(iterator)\n",
    "\n",
    "output = []\n",
    "for tweet in iterator[\"statuses\"]:\n",
    "        producer.send('Twitter', tweet)\n",
    "        print tweet\n",
    "        #print json.dumps(tweet, indent = 4)\n",
    "        #output.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tweets = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for tweets_data in output[1]:\n",
    "       #tweets_data\n",
    "#       print tweets_data\n",
    "'''\n",
    "tweets['text'] = map(lambda tweet: tweet['text'], output)\n",
    "tweets['lang'] = map(lambda tweet: tweet['lang'], output)\n",
    "tweets['country'] = map(lambda tweet: tweet['place']['country'] if tweet['place'] != None else None, output)\n",
    "tweets['user_nm'] = map(lambda tweet: tweet['user']['name'].encode('utf-8'), output)\n",
    "tweets['coordinates'] = map(lambda tweet: tweet['coordinates'], output)\n",
    "tweets['location'] = map(lambda tweet: tweet['user']['location'], output)\n",
    "tweets['retweets_count'] = map(lambda tweet: tweet['retweet_count'], output)\n",
    "tweets['text_clean'] = [re.sub(r\"http\\S+\", \"\", v) for v in tweets.text.values.tolist()]\n",
    "tweets['text_clean'] = [re.sub(r\"#\\S+\", \"\", v) for v in tweets.text_clean.values.tolist()]\n",
    "tweets['text_clean'] = [re.sub(r\"@\\S+\", \"\", v) for v in tweets.text_clean.values.tolist()]\n",
    "tweets['text_clean'] = [re.sub(r\"u'RT\\S+\", \"\", v) for v in tweets.text_clean.values.tolist()]\n",
    "tweets['text'] = [v.replace('\\n',\" \") for v in tweets.text.values.tolist()]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "tweets['text_clean'] = preprocessing.clean_text(text=tweets.text_clean.values, \n",
    "                         remove_short_tokens_flag=False,  \n",
    "                         lemmatize_flag=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "tweets['sentiment_score'] = [textfeatures.score_sentiment(v)['compound'] for v in tweets.text_clean.values.tolist()]\n",
    "tweets.loc[tweets['sentiment_score'] > 0.0, 'sentiment'] = 'positive'\n",
    "tweets.loc[tweets['sentiment_score'] == 0.0, 'sentiment'] = 'neutral'\n",
    "tweets.loc[tweets['sentiment_score'] < 0.0, 'sentiment'] = 'negative'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tweets.reset_index('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#producer.send('Twitter', tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#A = tweets.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#A = tweets.drop_duplicates(['text'], keep =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#A.duplicated(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
